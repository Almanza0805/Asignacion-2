{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Almanza0805/Asignacion-2/blob/main/assignaciones/assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6974964c",
      "metadata": {
        "id": "6974964c"
      },
      "source": [
        "# Clasificaci√≥n de Piso en el Dataset UJIIndoorLoc\n",
        "\n",
        "---\n",
        "\n",
        "## Introducci√≥n\n",
        "\n",
        "En este notebook se implementa un flujo completo de procesamiento y an√°lisis para la clasificaci√≥n del **piso** en un entorno interior utilizando el dataset **UJIIndoorLoc**. Este conjunto de datos contiene mediciones de se√±ales WiFi recopiladas en distintas ubicaciones de un edificio, con informaci√≥n sobre coordenadas, piso, usuario, hora, entre otros.\n",
        "\n",
        "En esta tarea nos enfocaremos en predecir el **piso** en el que se encuentra un dispositivo, considerando √∫nicamente las muestras etiquetadas con valores v√°lidos para dicha variable. Se tratar√° como un problema de clasificaci√≥n multiclase (planta baja, primer piso, segundo piso).\n",
        "\n",
        "## Objetivos\n",
        "\n",
        "- **Cargar y explorar** el conjunto de datos UJIIndoorLoc.\n",
        "- **Preparar** los datos seleccionando las caracter√≠sticas relevantes y el target (`FLOOR`).\n",
        "- **Dividir** el dataset en entrenamiento y validaci√≥n (80/20).\n",
        "- **Entrenar y optimizar** clasificadores basados en seis algoritmos:\n",
        "  - K-Nearest Neighbors (KNN)\n",
        "  - Gaussian Naive Bayes\n",
        "  - Regresi√≥n Log√≠stica\n",
        "  - √Årboles de Decisi√≥n\n",
        "  - Support Vector Machines (SVM)\n",
        "  - Random Forest\n",
        "- **Seleccionar hiperpar√°metros √≥ptimos** para cada modelo utilizando validaci√≥n cruzada (5-fold), empleando estrategias como **Grid Search**, **Randomized Search**, o **Bayesian Optimization** seg√∫n el algoritmo.\n",
        "- **Comparar el desempe√±o** de los modelos sobre el conjunto de validaci√≥n, usando m√©tricas como *accuracy*, *precision*, *recall*, y *F1-score*.\n",
        "- **Determinar el mejor clasificador** para esta tarea, junto con sus hiperpar√°metros √≥ptimos.\n",
        "\n",
        "Este ejercicio permite no solo evaluar la capacidad predictiva de distintos algoritmos cl√°sicos de clasificaci√≥n, sino tambi√©n desarrollar buenas pr√°cticas en validaci√≥n de modelos y selecci√≥n de hiperpar√°metros en contextos del mundo real.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "253ad8d2",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "253ad8d2"
      },
      "source": [
        "## Descripci√≥n del Dataset\n",
        "\n",
        "El dataset utilizado en este an√°lisis es el **UJIIndoorLoc Dataset**, ampliamente utilizado para tareas de localizaci√≥n en interiores a partir de se√±ales WiFi. Est√° disponible p√∫blicamente en la UCI Machine Learning Repository y ha sido recopilado en un entorno real de un edificio universitario.\n",
        "\n",
        "Cada muestra corresponde a una observaci√≥n realizada por un dispositivo m√≥vil, donde se registran las intensidades de se√±al (RSSI) de m√°s de 500 puntos de acceso WiFi disponibles en el entorno. Adem√°s, cada fila contiene informaci√≥n contextual como la ubicaci√≥n real del dispositivo (coordenadas X e Y), el piso, el edificio, el identificador del usuario, y la marca temporal.\n",
        "\n",
        "El objetivo en esta tarea es predecir el **piso** (`FLOOR`) en el que se encontraba el dispositivo en el momento de la medici√≥n, considerando √∫nicamente las caracter√≠sticas num√©ricas provenientes de las se√±ales WiFi.\n",
        "\n",
        "### Estructura del dataset\n",
        "\n",
        "- **N√∫mero de muestras**: ~20,000\n",
        "- **N√∫mero de caracter√≠sticas**: 520\n",
        "  - 520 columnas con valores de intensidad de se√±al WiFi (`WAP001` a `WAP520`)\n",
        "- **Variable objetivo**: `FLOOR` (variable categ√≥rica con m√∫ltiples clases, usualmente entre 0 y 4)\n",
        "\n",
        "### Columnas relevantes\n",
        "\n",
        "- `WAP001`, `WAP002`, ..., `WAP520`: niveles de se√±al recibida desde cada punto de acceso WiFi (valores entre -104 y 0, o 100 si no se detect√≥).\n",
        "- `FLOOR`: clase objetivo a predecir (nivel del edificio).\n",
        "- (Otras columnas como `BUILDINGID`, `SPACEID`, `USERID`, `TIMESTAMP`, etc., pueden ser ignoradas o utilizadas en an√°lisis complementarios).\n",
        "\n",
        "### Contexto del problema\n",
        "\n",
        "La localizaci√≥n en interiores es un problema complejo en el que tecnolog√≠as como el GPS no funcionan adecuadamente. Los sistemas basados en WiFi han demostrado ser una alternativa efectiva para estimar la ubicaci√≥n de usuarios en edificios. Poder predecir autom√°ticamente el piso en el que se encuentra una persona puede mejorar aplicaciones de navegaci√≥n en interiores, accesibilidad, gesti√≥n de emergencias y servicios personalizados. Este tipo de problemas es t√≠picamente abordado mediante algoritmos de clasificaci√≥n multiclase.\n",
        "\n",
        "\n",
        "### Estrategia de evaluaci√≥n\n",
        "\n",
        "En este an√°lisis seguiremos una metodolog√≠a rigurosa para garantizar la validez de los resultados:\n",
        "\n",
        "1. **Dataset de entrenamiento**: Se utilizar√° exclusivamente para el desarrollo, entrenamiento y optimizaci√≥n de hiperpar√°metros de todos los modelos. Este conjunto ser√° dividido internamente en subconjuntos de entrenamiento y validaci√≥n (80/20) para la selecci√≥n de hiperpar√°metros mediante validaci√≥n cruzada.\n",
        "\n",
        "2. **Dataset de prueba**: Se reservar√° √∫nicamente para la **evaluaci√≥n final** de los modelos ya optimizados. Este conjunto **no debe ser utilizado** durante el proceso de selecci√≥n de hiperpar√°metros, ajuste de modelos o toma de decisiones sobre la arquitectura, ya que esto introducir√≠a sesgo y comprometer√≠a la capacidad de generalizaci√≥n estimada.\n",
        "\n",
        "3. **Validaci√≥n cruzada**: Para la optimizaci√≥n de hiperpar√°metros se emplear√° validaci√≥n cruzada 5-fold sobre el conjunto de entrenamiento, lo que permitir√° una estimaci√≥n robusta del rendimiento sin contaminar los datos de prueba.\n",
        "\n",
        "Esta separaci√≥n estricta entre datos de desarrollo y evaluaci√≥n final es fundamental para obtener una estimaci√≥n realista del rendimiento que los modelos tendr√≠an en un escenario de producci√≥n con datos completamente nuevos.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b4b8e4d",
      "metadata": {
        "id": "0b4b8e4d"
      },
      "source": [
        "## Paso 1: Cargar y explorar el dataset\n",
        "\n",
        "**Instrucciones:**\n",
        "- Descarga el dataset **UJIIndoorLoc** desde la UCI Machine Learning Repository o utiliza la versi√≥n proporcionada en el repositorio del curso (por ejemplo: `datasets\\UJIIndoorLoc\\trainingData.csv`).\n",
        "- Carga el dataset utilizando `pandas`.\n",
        "- Muestra las primeras filas del dataset utilizando `df.head()`.\n",
        "- Imprime el n√∫mero total de muestras (filas) y caracter√≠sticas (columnas).\n",
        "- Verifica cu√°ntas clases distintas hay en la variable objetivo `FLOOR` y cu√°ntas muestras tiene cada clase (`df['FLOOR'].value_counts()`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d27f8d5",
      "metadata": {
        "id": "2d27f8d5"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Cargar el archivo subido (ajusta el nombre si es diferente)\n",
        "df = pd.read_csv(\"trainingData.csv\")\n",
        "\n",
        "# Ver primeras filas\n",
        "print(\"üîç Primeras filas:\")\n",
        "display(df.head())\n",
        "\n",
        "# Tama√±o del dataset\n",
        "print(f\"\\nüìä Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n",
        "\n",
        "# Ver clases en la variable FLOOR\n",
        "print(\"\\nüìå Conteo de clases en FLOOR:\")\n",
        "print(df['FLOOR'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e2f0bed",
      "metadata": {
        "id": "2e2f0bed"
      },
      "source": [
        "---\n",
        "\n",
        "## Paso 2: Preparar los datos\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "- Elimina las columnas que no son relevantes para la tarea de clasificaci√≥n del piso:\n",
        "  - `LONGITUDE`, `LATITUDE`, `SPACEID`, `RELATIVEPOSITION`, `USERID`, `PHONEID`, `TIMESTAMP`\n",
        "- Conserva √∫nicamente:\n",
        "  - Las columnas `WAP001` a `WAP520` como caracter√≠sticas (RSSI de puntos de acceso WiFi).\n",
        "  - La columna `FLOOR` como variable objetivo.\n",
        "- Verifica si existen valores at√≠picos o valores inv√°lidos en las se√±ales WiFi (por ejemplo: valores constantes como 100 o -110 que suelen indicar ausencia de se√±al).\n",
        "- Separa el conjunto de datos en:\n",
        "  - `X`: matriz de caracter√≠sticas (todas las columnas `WAP`)\n",
        "  - `y`: vector objetivo (`FLOOR`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f0eec3c",
      "metadata": {
        "id": "9f0eec3c"
      },
      "outputs": [],
      "source": [
        "# Eliminar solo las columnas que realmente existan\n",
        "columnas_a_eliminar = ['LONGITUDE', 'LATITUDE', 'SPACEID', 'RELATIVEPOSITION', 'USERID', 'PHONEID', 'TIMESTAMP']\n",
        "df = df.drop(columns=[col for col in columnas_a_eliminar if col in df.columns])\n",
        "\n",
        "# Separar variables\n",
        "X = df.iloc[:, 0:520]\n",
        "y = df['FLOOR']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e8a6c39",
      "metadata": {
        "id": "3e8a6c39"
      },
      "source": [
        "---\n",
        "\n",
        "## Paso 3: Preprocesamiento de las se√±ales WiFi\n",
        "\n",
        "**Contexto:**\n",
        "\n",
        "Las columnas `WAP001` a `WAP520` representan la intensidad de la se√±al (RSSI) recibida desde distintos puntos de acceso WiFi. Los valores t√≠picos de RSSI est√°n en una escala negativa, donde:\n",
        "\n",
        "- Valores cercanos a **0 dBm** indican se√±al fuerte.\n",
        "- Valores cercanos a **-100 dBm** indican se√±al d√©bil o casi ausente.\n",
        "- Un valor de **100** en este dataset representa una se√±al **no detectada**, es decir, el punto de acceso no fue visto por el dispositivo en ese instante.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "- Para facilitar el procesamiento y tratar la ausencia de se√±al de forma coherente, se recomienda mapear todos los valores **100** a **-100**, que sem√°nticamente representa *ausencia de se√±al detectable*.\n",
        "- Esto unifica el rango de valores y evita que 100 (un valor artificial) afecte negativamente la escala de los algoritmos.\n",
        "\n",
        "**Pasos sugeridos:**\n",
        "\n",
        "- Reemplaza todos los valores `100` por `-100` en las columnas `WAP001` a `WAP520`:\n",
        "  ```python\n",
        "  X[X == 100] = -100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61fa6fe3",
      "metadata": {
        "id": "61fa6fe3"
      },
      "outputs": [],
      "source": [
        "# Reemplazar valores 100 por -100 en las columnas de caracter√≠sticas WiFi\n",
        "X[X == 100] = -100\n",
        "\n",
        "# Verificaci√≥n r√°pida: ¬øa√∫n hay valores 100?\n",
        "print(f\"‚úîÔ∏è ¬øA√∫n hay valores 100?: {(X == 100).any().any()}\")  # Esto debe imprimir False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80383336",
      "metadata": {
        "id": "80383336"
      },
      "source": [
        "---\n",
        "\n",
        "## Paso 4: Entrenamiento y optimizaci√≥n de hiperpar√°metros\n",
        "\n",
        "**Objetivo:**\n",
        "\n",
        "Entrenar y comparar distintos clasificadores para predecir correctamente el piso (`FLOOR`) y encontrar los mejores hiperpar√°metros para cada uno mediante validaci√≥n cruzada.\n",
        "\n",
        "**Clasificadores a evaluar:**\n",
        "\n",
        "- K-Nearest Neighbors (KNN)\n",
        "- Gaussian Naive Bayes\n",
        "- Regresi√≥n Log√≠stica\n",
        "- √Årboles de Decisi√≥n\n",
        "- Support Vector Machines (SVM)\n",
        "- Random Forest\n",
        "\n",
        "**Procedimiento:**\n",
        "\n",
        "1. Divide el dataset en conjunto de **entrenamiento** (80%) y **validaci√≥n** (20%) usando `train_test_split` con `stratify=y`.\n",
        "2. Para cada clasificador:\n",
        "   - Define el espacio de b√∫squeda de hiperpar√°metros.\n",
        "   - Usa **validaci√≥n cruzada 5-fold** sobre el conjunto de entrenamiento para seleccionar los mejores hiperpar√°metros.\n",
        "   - Emplea una estrategia de b√∫squeda adecuada:\n",
        "     - **GridSearchCV**: b√∫squeda exhaustiva (ideal para espacios peque√±os).\n",
        "     - **RandomizedSearchCV**: b√∫squeda aleatoria (m√°s eficiente con espacios amplios).\n",
        "     - **Bayesian Optimization** (opcional): para b√∫squedas m√°s inteligentes, usando librer√≠as como `optuna` o `skopt`.\n",
        "3. Guarda el mejor modelo encontrado para cada clasificador con su configuraci√≥n √≥ptima.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87cd1be",
      "metadata": {
        "id": "f87cd1be"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Entrenamiento: {X_train.shape}, Validaci√≥n: {X_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "850e98ec",
      "metadata": {
        "id": "850e98ec"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_knn.fit(X_train, y_train)\n",
        "\n",
        "best_knn = grid_knn.best_estimator_\n",
        "print(\"üèÜ Mejor KNN:\", grid_knn.best_params_)\n",
        "print(classification_report(y_val, best_knn.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34cc6ca0",
      "metadata": {
        "id": "34cc6ca0"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "y_pred_gnb = gnb.predict(X_val)\n",
        "print(\"üìä Gaussian Naive Bayes:\")\n",
        "print(classification_report(y_val, y_pred_gnb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da7bc6f7",
      "metadata": {
        "id": "da7bc6f7"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid_lr = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'solver': ['lbfgs', 'liblinear'],\n",
        "    'max_iter': [500]\n",
        "}\n",
        "\n",
        "grid_lr = GridSearchCV(LogisticRegression(multi_class='auto'), param_grid_lr, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_lr.fit(X_train, y_train)\n",
        "\n",
        "best_lr = grid_lr.best_estimator_\n",
        "print(\"üèÜ Mejor Logistic Regression:\", grid_lr.best_params_)\n",
        "print(classification_report(y_val, best_lr.predict(X_val)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1fca347",
      "metadata": {
        "id": "f1fca347"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "param_grid_dt = {\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_dt = GridSearchCV(DecisionTreeClassifier(), param_grid_dt, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_dt.fit(X_train, y_train)\n",
        "\n",
        "best_dt = grid_dt.best_estimator_\n",
        "print(\"üèÜ Mejor √Årbol de Decisi√≥n:\", grid_dt.best_params_)\n",
        "print(classification_report(y_val, best_dt.predict(X_val)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cdbe3e3",
      "metadata": {
        "id": "5cdbe3e3"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf']\n",
        "}\n",
        "\n",
        "grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "best_svm = grid_svm.best_estimator_\n",
        "print(\"üèÜ Mejor SVM:\", grid_svm.best_params_)\n",
        "print(classification_report(y_val, best_svm.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38458a23",
      "metadata": {
        "id": "38458a23"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "best_rf = grid_rf.best_estimator_\n",
        "print(\"üèÜ Mejor Random Forest:\", grid_rf.best_params_)\n",
        "print(classification_report(y_val, best_rf.predict(X_val)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64de7a7c",
      "metadata": {
        "id": "64de7a7c"
      },
      "source": [
        "---\n",
        "\n",
        "## Paso 5: Crear una tabla resumen de los mejores modelos\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "Despu√©s de entrenar y optimizar todos los clasificadores, debes construir una **tabla resumen en formato Markdown** que incluya:\n",
        "\n",
        "- El **nombre del modelo**\n",
        "- Los **hiperpar√°metros √≥ptimos** encontrados mediante validaci√≥n cruzada\n",
        "\n",
        "### Requisitos:\n",
        "\n",
        "- La tabla debe estar escrita en formato **Markdown**.\n",
        "- Cada fila debe corresponder a uno de los modelos evaluados.\n",
        "- Incluye solo los **mejores hiperpar√°metros** para cada modelo, es decir, aquellos que produjeron el mayor rendimiento en la validaci√≥n cruzada (accuracy o F1-score).\n",
        "- No incluyas a√∫n las m√©tricas de evaluaci√≥n (eso se har√° en el siguiente paso).\n",
        "\n",
        "### Ejemplo de formato:\n",
        "\n",
        "\n",
        "| Modelo                 | Hiperpar√°metros √≥ptimos                            |\n",
        "|------------------------|----------------------------------------------------|\n",
        "| KNN                    | n_neighbors=5, weights='distance'                  |\n",
        "| Gaussian Naive Bayes   | var_smoothing=1e-9 (por defecto)                   |\n",
        "| Regresi√≥n Log√≠stica    | C=1.0, solver='lbfgs'                              |\n",
        "| √Årbol de Decisi√≥n      | max_depth=10, criterion='entropy'                  |\n",
        "| SVM                    | C=10, kernel='rbf', gamma='scale'                  |\n",
        "| Random Forest          | n_estimators=200, max_depth=20                     |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5db06abe",
      "metadata": {
        "id": "5db06abe"
      },
      "source": [
        "# tu tabla de resultados aqu√≠"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc8951e6",
      "metadata": {
        "id": "bc8951e6"
      },
      "source": [
        "---\n",
        "\n",
        "## Paso 6: Preparar los datos finales para evaluaci√≥n\n",
        "\n",
        "**Objetivo:**\n",
        "Cargar el dataset de entrenamiento y prueba, limpiar las columnas innecesarias, ajustar los valores de se√±al, y dejar los datos listos para probar los modelos entrenados.\n",
        "\n",
        "**Instrucciones:**\n",
        "Implementa una funci√≥n que:\n",
        "- Cargue los archivos `trainingData.csv` y `validationData.csv`\n",
        "- Elimine las columnas irrelevantes (`LONGITUDE`, `LATITUDE`, `SPACEID`, `RELATIVEPOSITION`, `USERID`, `PHONEID`, `TIMESTAMP`)\n",
        "- Reemplace los valores `100` por `-100` en las columnas `WAP001` a `WAP520`\n",
        "- Separe las caracter√≠sticas (`X`) y la variable objetivo (`FLOOR`)\n",
        "- Devuelva los conjuntos `X_train`, `X_test`, `y_train`, `y_test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2519692",
      "metadata": {
        "id": "a2519692"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def preparar_datos_finales(train_path='trainingData.csv', test_path='validationData.csv'):\n",
        "    # 1. Cargar los archivos\n",
        "    df_train = pd.read_csv(train_path)\n",
        "    df_test = pd.read_csv(test_path)\n",
        "\n",
        "    # 2. Columnas irrelevantes a eliminar\n",
        "    columnas_a_eliminar = ['LONGITUDE', 'LATITUDE', 'SPACEID',\n",
        "                           'RELATIVEPOSITION', 'USERID', 'PHONEID', 'TIMESTAMP']\n",
        "\n",
        "    # Eliminar solo si existen (por seguridad)\n",
        "    df_train = df_train.drop(columns=[col for col in columnas_a_eliminar if col in df_train.columns])\n",
        "    df_test = df_test.drop(columns=[col for col in columnas_a_eliminar if col in df_test.columns])\n",
        "\n",
        "    # 3. Reemplazar 100 por -100 en las columnas WAP001 a WAP520\n",
        "    wap_cols = [col for col in df_train.columns if col.startswith('WAP')]\n",
        "    df_train[wap_cols] = df_train[wap_cols].replace(100, -100)\n",
        "    df_test[wap_cols] = df_test[wap_cols].replace(100, -100)\n",
        "\n",
        "    # 4. Separar caracter√≠sticas y variable objetivo\n",
        "    X_train = df_train[wap_cols]\n",
        "    y_train = df_train['FLOOR']\n",
        "\n",
        "    X_test = df_test[wap_cols]\n",
        "    y_test = df_test['FLOOR']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1e1611e",
      "metadata": {
        "id": "a1e1611e"
      },
      "source": [
        "---\n",
        "\n",
        "## Paso 7: Evaluar modelos optimizados en el conjunto de prueba\n",
        "\n",
        "**Objetivo:**\n",
        "Evaluar el rendimiento real de los modelos optimizados usando el conjunto de prueba (`X_test`, `y_test`), previamente separado. Cada modelo debe ser entrenado nuevamente sobre **todo el conjunto de entrenamiento** (`X_train`, `y_train`) con sus mejores hiperpar√°metros, y luego probado en `X_test`.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1. Para cada modelo:\n",
        "   - Usa los **hiperpar√°metros √≥ptimos** encontrados en el Paso 4.\n",
        "   - Entrena el modelo con `X_train` y `y_train`.\n",
        "   - Calcula y guarda:\n",
        "     - `Accuracy`\n",
        "     - `Precision` (macro)\n",
        "     - `Recall` (macro)\n",
        "     - `F1-score` (macro)\n",
        "     - `AUC` (promedio one-vs-rest si es multiclase)\n",
        "     - Tiempo de entrenamiento (`train_time`)\n",
        "     - Tiempo de predicci√≥n (`test_time`)\n",
        "2. Muestra todos los resultados en una **tabla comparativa**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10347fe7",
      "metadata": {
        "id": "10347fe7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import time\n",
        "import pandas as pd\n",
        "def preparar_datos_finales(train_path='trainingData.csv', test_path='validationData.csv'):\n",
        "    import pandas as pd\n",
        "\n",
        "    # Cargar archivos CSV\n",
        "    df_train = pd.read_csv(train_path)\n",
        "    df_test = pd.read_csv(test_path)\n",
        "\n",
        "    # Columnas a eliminar\n",
        "    columnas_a_eliminar = ['LONGITUDE', 'LATITUDE', 'SPACEID',\n",
        "                           'RELATIVEPOSITION', 'USERID', 'PHONEID', 'TIMESTAMP']\n",
        "\n",
        "    # Eliminar columnas irrelevantes si existen\n",
        "    df_train = df_train.drop(columns=[col for col in columnas_a_eliminar if col in df_train.columns])\n",
        "    df_test = df_test.drop(columns=[col for col in columnas_a_eliminar if col in df_test.columns])\n",
        "\n",
        "    # Reemplazar 100 por -100\n",
        "    wap_cols = [col for col in df_train.columns if col.startswith('WAP')]\n",
        "    df_train[wap_cols] = df_train[wap_cols].replace(100, -100)\n",
        "    df_test[wap_cols] = df_test[wap_cols].replace(100, -100)\n",
        "\n",
        "    # Separar caracter√≠sticas y variable objetivo\n",
        "    X_train = df_train[wap_cols]\n",
        "    y_train = df_train['FLOOR']\n",
        "    X_test = df_test[wap_cols]\n",
        "    y_test = df_test['FLOOR']\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train_final, X_test_final, y_train_final, y_test_final = preparar_datos_finales()\n",
        "\n",
        "# Evaluar todos los modelos\n",
        "resultados_modelos = []\n",
        "\n",
        "for nombre, modelo in modelos.items():\n",
        "    print(f\"‚è≥ Evaluando: {nombre}\")\n",
        "    resultados = evaluar_modelo(modelo, X_train_final, y_train_final, X_test_final, y_test_final)\n",
        "    resultados['modelo'] = nombre\n",
        "    resultados_modelos.append(resultados)\n",
        "\n",
        "# Mostrar tabla de resultados\n",
        "df_resultados = pd.DataFrame(resultados_modelos)\n",
        "df_resultados = df_resultados[['modelo', 'accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'auc_macro', 'train_time', 'test_time']]\n",
        "df_resultados.sort_values(by='f1_macro', ascending=False, inplace=True)\n",
        "df_resultados.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df_resultados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efcf813b",
      "metadata": {
        "id": "efcf813b"
      },
      "source": [
        "---\n",
        "## Paso 8: Selecci√≥n y justificaci√≥n del mejor modelo\n",
        "\n",
        "**Objetivo:**\n",
        "Analizar los resultados obtenidos en el paso anterior y **emitir una conclusi√≥n razonada** sobre cu√°l de los modelos evaluados es el m√°s adecuado para la tarea de predicci√≥n del piso en el dataset UJIIndoorLoc.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "- Observa la tabla comparativa del Paso 7 y responde:\n",
        "  - ¬øQu√© modelo obtuvo el **mejor rendimiento general** en t√©rminos de **accuracy** y **F1-score**?\n",
        "  - ¬øQu√© tan consistente fue su rendimiento en **precision** y **recall**?\n",
        "  - ¬øTiene un **tiempo de entrenamiento o inferencia** excesivamente alto?\n",
        "  - ¬øEl modelo necesita **normalizaci√≥n**, muchos recursos o ajustes delicados?\n",
        "- Bas√°ndote en estos aspectos, **elige un solo modelo** como el mejor clasificador para esta tarea.\n",
        "- **Justifica tu elecci√≥n** considerando tanto el desempe√±o como la eficiencia y facilidad de implementaci√≥n.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7a61042",
      "metadata": {
        "id": "e7a61042"
      },
      "source": [
        "# tu respuesta aqu√≠\n",
        "\n",
        "#### üìã Tabla resumen de modelos y sus mejores hiperpar√°metros\n",
        "\n",
        "| Modelo                  | Hiperpar√°metros √≥ptimos                                              |\n",
        "|-------------------------|-----------------------------------------------------------------------|\n",
        "| KNN                     | `n_neighbors=5`, `weights='distance'`, `metric='manhattan'`          |\n",
        "| Gaussian Naive Bayes    | No requiere ajuste (usa valores por defecto)                         |\n",
        "| Regresi√≥n Log√≠stica     | `C=1`, `solver='liblinear'`, `max_iter=500`                          |\n",
        "| √Årbol de Decisi√≥n       | `max_depth=20`, `min_samples_split=5`                                |\n",
        "| SVM                     | `C=10`, `kernel='rbf'`, `probability=True`                           |\n",
        "| Random Forest           | `n_estimators=100`, `max_depth=None`, `min_samples_split=2`          |\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Modelo Seleccionado: **SVM (Support Vector Machine)**\n",
        "\n",
        "#### Justificaci√≥n:\n",
        "\n",
        "1. **Rendimiento predictivo sobresaliente:**\n",
        "   - Obtuvo la mayor **accuracy** (`0.9217`) y **F1-score macro** (`0.9148`) entre todos los modelos evaluados.\n",
        "   - Adem√°s, tuvo **alta precision (`0.9100`) y recall (`0.9210`)**, indicando equilibrio y bajo sesgo.\n",
        "\n",
        "2. **Capacidad de discriminaci√≥n:**\n",
        "   - El valor de **AUC macro = 0.9848** muestra un excelente rendimiento multiclase.\n",
        "\n",
        "3. **Tiempo y eficiencia:**\n",
        "   - Aunque el tiempo de entrenamiento fue el m√°s alto (`71.7s`), el de inferencia (`1.82s`) es aceptable.\n",
        "   - No es el m√°s r√°pido, pero su **desempe√±o justifica el costo computacional**.\n",
        "\n",
        "4. **Implementaci√≥n:**\n",
        "   - Requiere normalizaci√≥n y ajuste fino de hiperpar√°metros, pero no necesita cambios frecuentes una vez afinado.\n",
        "\n",
        "---\n",
        "\n",
        "### üèÅ Conclusi√≥n:\n",
        "\n",
        "**SVM** es el modelo m√°s adecuado para predecir el piso en entornos interiores usando el dataset UJIIndoorLoc. Su desempe√±o superior, estabilidad y capacidad de generalizaci√≥n lo convierten en la opci√≥n ideal para esta tarea.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f47b37a",
      "metadata": {
        "id": "8f47b37a"
      },
      "source": [
        "---\n",
        "\n",
        "## R√∫brica de Evaluaci√≥n\n",
        "\n",
        "| Paso | Descripci√≥n | Puntuaci√≥n |\n",
        "|------|-------------|------------|\n",
        "| 1 | Cargar y explorar el dataset | 5 |\n",
        "| 2 | Preparar los datos | 5 |\n",
        "| 3 | Preprocesamiento de las se√±ales WiFi | 10 |\n",
        "| 4 | Entrenamiento y optimizaci√≥n de hiperpar√°metros | 40 |\n",
        "| 5 | Crear una tabla resumen de los mejores modelos | 5 |\n",
        "| 6 | Preparar los datos finales para evaluaci√≥n | 5 |\n",
        "| 7 | Evaluar modelos optimizados en el conjunto de prueba | 10 |\n",
        "| 8 | Selecci√≥n y justificaci√≥n del mejor modelo | 20 |\n",
        "| **Total** | | **100** |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}