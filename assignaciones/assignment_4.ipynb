{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Almanza0805/Asignacion-2/blob/main/assignaciones/assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6974964c",
      "metadata": {
        "id": "6974964c"
      },
      "source": [
        "# Clasificación de Piso en el Dataset UJIIndoorLoc\n",
        "\n",
        "---\n",
        "\n",
        "## Introducción\n",
        "\n",
        "En este notebook se implementa un flujo completo de procesamiento y análisis para la clasificación del **piso** en un entorno interior utilizando el dataset **UJIIndoorLoc**. Este conjunto de datos contiene mediciones de señales WiFi recopiladas en distintas ubicaciones de un edificio, con información sobre coordenadas, piso, usuario, hora, entre otros.\n",
        "\n",
        "En esta tarea nos enfocaremos en predecir el **piso** en el que se encuentra un dispositivo, considerando únicamente las muestras etiquetadas con valores válidos para dicha variable. Se tratará como un problema de clasificación multiclase (planta baja, primer piso, segundo piso).\n",
        "\n",
        "## Objetivos\n",
        "\n",
        "- **Cargar y explorar** el conjunto de datos UJIIndoorLoc.\n",
        "- **Preparar** los datos seleccionando las características relevantes y el target (`FLOOR`).\n",
        "- **Dividir** el dataset en entrenamiento y validación (80/20).\n",
        "- **Entrenar y optimizar** clasificadores basados en seis algoritmos:\n",
        "  - K-Nearest Neighbors (KNN)\n",
        "  - Gaussian Naive Bayes\n",
        "  - Regresión Logística\n",
        "  - Árboles de Decisión\n",
        "  - Support Vector Machines (SVM)\n",
        "  - Random Forest\n",
        "- **Seleccionar hiperparámetros óptimos** para cada modelo utilizando validación cruzada (5-fold), empleando estrategias como **Grid Search**, **Randomized Search**, o **Bayesian Optimization** según el algoritmo.\n",
        "- **Comparar el desempeño** de los modelos sobre el conjunto de validación, usando métricas como *accuracy*, *precision*, *recall*, y *F1-score*.\n",
        "- **Determinar el mejor clasificador** para esta tarea, junto con sus hiperparámetros óptimos.\n",
        "\n",
        "Este ejercicio permite no solo evaluar la capacidad predictiva de distintos algoritmos clásicos de clasificación, sino también desarrollar buenas prácticas en validación de modelos y selección de hiperparámetros en contextos del mundo real.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "253ad8d2",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "253ad8d2"
      },
      "source": [
        "## Descripción del Dataset\n",
        "\n",
        "El dataset utilizado en este análisis es el **UJIIndoorLoc Dataset**, ampliamente utilizado para tareas de localización en interiores a partir de señales WiFi. Está disponible públicamente en la UCI Machine Learning Repository y ha sido recopilado en un entorno real de un edificio universitario.\n",
        "\n",
        "Cada muestra corresponde a una observación realizada por un dispositivo móvil, donde se registran las intensidades de señal (RSSI) de más de 500 puntos de acceso WiFi disponibles en el entorno. Además, cada fila contiene información contextual como la ubicación real del dispositivo (coordenadas X e Y), el piso, el edificio, el identificador del usuario, y la marca temporal.\n",
        "\n",
        "El objetivo en esta tarea es predecir el **piso** (`FLOOR`) en el que se encontraba el dispositivo en el momento de la medición, considerando únicamente las características numéricas provenientes de las señales WiFi.\n",
        "\n",
        "### Estructura del dataset\n",
        "\n",
        "- **Número de muestras**: ~20,000\n",
        "- **Número de características**: 520\n",
        "  - 520 columnas con valores de intensidad de señal WiFi (`WAP001` a `WAP520`)\n",
        "- **Variable objetivo**: `FLOOR` (variable categórica con múltiples clases, usualmente entre 0 y 4)\n",
        "\n",
        "### Columnas relevantes\n",
        "\n",
        "- `WAP001`, `WAP002`, ..., `WAP520`: niveles de señal recibida desde cada punto de acceso WiFi (valores entre -104 y 0, o 100 si no se detectó).\n",
        "- `FLOOR`: clase objetivo a predecir (nivel del edificio).\n",
        "- (Otras columnas como `BUILDINGID`, `SPACEID`, `USERID`, `TIMESTAMP`, etc., pueden ser ignoradas o utilizadas en análisis complementarios).\n",
        "\n",
        "### Contexto del problema\n",
        "\n",
        "La localización en interiores es un problema complejo en el que tecnologías como el GPS no funcionan adecuadamente. Los sistemas basados en WiFi han demostrado ser una alternativa efectiva para estimar la ubicación de usuarios en edificios. Poder predecir automáticamente el piso en el que se encuentra una persona puede mejorar aplicaciones de navegación en interiores, accesibilidad, gestión de emergencias y servicios personalizados. Este tipo de problemas es típicamente abordado mediante algoritmos de clasificación multiclase.\n",
        "\n",
        "\n",
        "### Estrategia de evaluación\n",
        "\n",
        "En este análisis seguiremos una metodología rigurosa para garantizar la validez de los resultados:\n",
        "\n",
        "1. **Dataset de entrenamiento**: Se utilizará exclusivamente para el desarrollo, entrenamiento y optimización de hiperparámetros de todos los modelos. Este conjunto será dividido internamente en subconjuntos de entrenamiento y validación (80/20) para la selección de hiperparámetros mediante validación cruzada.\n",
        "\n",
        "2. **Dataset de prueba**: Se reservará únicamente para la **evaluación final** de los modelos ya optimizados. Este conjunto **no debe ser utilizado** durante el proceso de selección de hiperparámetros, ajuste de modelos o toma de decisiones sobre la arquitectura, ya que esto introduciría sesgo y comprometería la capacidad de generalización estimada.\n",
        "\n",
        "3. **Validación cruzada**: Para la optimización de hiperparámetros se empleará validación cruzada 5-fold sobre el conjunto de entrenamiento, lo que permitirá una estimación robusta del rendimiento sin contaminar los datos de prueba.\n",
        "\n",
        "Esta separación estricta entre datos de desarrollo y evaluación final es fundamental para obtener una estimación realista del rendimiento que los modelos tendrían en un escenario de producción con datos completamente nuevos.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b4b8e4d",
      "metadata": {
        "id": "0b4b8e4d"
      },
      "source": [
        "## Paso 1: Cargar y explorar el dataset\n",
        "\n",
        "**Instrucciones:**\n",
        "- Descarga el dataset **UJIIndoorLoc** desde la UCI Machine Learning Repository o utiliza la versión proporcionada en el repositorio del curso (por ejemplo: `datasets\\UJIIndoorLoc\\trainingData.csv`).\n",
        "- Carga el dataset utilizando `pandas`.\n",
        "- Muestra las primeras filas del dataset utilizando `df.head()`.\n",
        "- Imprime el número total de muestras (filas) y características (columnas).\n",
        "- Verifica cuántas clases distintas hay en la variable objetivo `FLOOR` y cuántas muestras tiene cada clase (`df['FLOOR'].value_counts()`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d27f8d5",
      "metadata": {
        "id": "2d27f8d5"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Cargar el archivo subido (ajusta el nombre si es diferente)\n",
        "df = pd.read_csv(\"trainingData.csv\")\n",
        "\n",
        "# Ver primeras filas\n",
        "print(\"🔍 Primeras filas:\")\n",
        "display(df.head())\n",
        "\n",
        "# Tamaño del dataset\n",
        "print(f\"\\n📊 Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n",
        "\n",
        "# Ver clases en la variable FLOOR\n",
        "print(\"\\n📌 Conteo de clases en FLOOR:\")\n",
        "print(df['FLOOR'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e2f0bed",
      "metadata": {
        "id": "2e2f0bed"
      },
      "source": [
        "---\n",
        "\n",
        "## Paso 2: Preparar los datos\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "- Elimina las columnas que no son relevantes para la tarea de clasificación del piso:\n",
        "  - `LONGITUDE`, `LATITUDE`, `SPACEID`, `RELATIVEPOSITION`, `USERID`, `PHONEID`, `TIMESTAMP`\n",
        "- Conserva únicamente:\n",
        "  - Las columnas `WAP001` a `WAP520` como características (RSSI de puntos de acceso WiFi).\n",
        "  - La columna `FLOOR` como variable objetivo.\n",
        "- Verifica si existen valores atípicos o valores inválidos en las señales WiFi (por ejemplo: valores constantes como 100 o -110 que suelen indicar ausencia de señal).\n",
        "- Separa el conjunto de datos en:\n",
        "  - `X`: matriz de características (todas las columnas `WAP`)\n",
        "  - `y`: vector objetivo (`FLOOR`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f0eec3c",
      "metadata": {
        "id": "9f0eec3c"
      },
      "outputs": [],
      "source": [
        "# Eliminar solo las columnas que realmente existan\n",
        "columnas_a_eliminar = ['LONGITUDE', 'LATITUDE', 'SPACEID', 'RELATIVEPOSITION', 'USERID', 'PHONEID', 'TIMESTAMP']\n",
        "df = df.drop(columns=[col for col in columnas_a_eliminar if col in df.columns])\n",
        "\n",
        "# Separar variables\n",
        "X = df.iloc[:, 0:520]\n",
        "y = df['FLOOR']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e8a6c39",
      "metadata": {
        "id": "3e8a6c39"
      },
      "source": [
        "---\n",
        "\n",
        "## Paso 3: Preprocesamiento de las señales WiFi\n",
        "\n",
        "**Contexto:**\n",
        "\n",
        "Las columnas `WAP001` a `WAP520` representan la intensidad de la señal (RSSI) recibida desde distintos puntos de acceso WiFi. Los valores típicos de RSSI están en una escala negativa, donde:\n",
        "\n",
        "- Valores cercanos a **0 dBm** indican señal fuerte.\n",
        "- Valores cercanos a **-100 dBm** indican señal débil o casi ausente.\n",
        "- Un valor de **100** en este dataset representa una señal **no detectada**, es decir, el punto de acceso no fue visto por el dispositivo en ese instante.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "- Para facilitar el procesamiento y tratar la ausencia de señal de forma coherente, se recomienda mapear todos los valores **100** a **-100**, que semánticamente representa *ausencia de señal detectable*.\n",
        "- Esto unifica el rango de valores y evita que 100 (un valor artificial) afecte negativamente la escala de los algoritmos.\n",
        "\n",
        "**Pasos sugeridos:**\n",
        "\n",
        "- Reemplaza todos los valores `100` por `-100` en las columnas `WAP001` a `WAP520`:\n",
        "  ```python\n",
        "  X[X == 100] = -100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61fa6fe3",
      "metadata": {
        "id": "61fa6fe3"
      },
      "outputs": [],
      "source": [
        "# Reemplazar valores 100 por -100 en las columnas de características WiFi\n",
        "X[X == 100] = -100\n",
        "\n",
        "# Verificación rápida: ¿aún hay valores 100?\n",
        "print(f\"✔️ ¿Aún hay valores 100?: {(X == 100).any().any()}\")  # Esto debe imprimir False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80383336",
      "metadata": {
        "id": "80383336"
      },
      "source": [
        "---\n",
        "\n",
        "## Paso 4: Entrenamiento y optimización de hiperparámetros\n",
        "\n",
        "**Objetivo:**\n",
        "\n",
        "Entrenar y comparar distintos clasificadores para predecir correctamente el piso (`FLOOR`) y encontrar los mejores hiperparámetros para cada uno mediante validación cruzada.\n",
        "\n",
        "**Clasificadores a evaluar:**\n",
        "\n",
        "- K-Nearest Neighbors (KNN)\n",
        "- Gaussian Naive Bayes\n",
        "- Regresión Logística\n",
        "- Árboles de Decisión\n",
        "- Support Vector Machines (SVM)\n",
        "- Random Forest\n",
        "\n",
        "**Procedimiento:**\n",
        "\n",
        "1. Divide el dataset en conjunto de **entrenamiento** (80%) y **validación** (20%) usando `train_test_split` con `stratify=y`.\n",
        "2. Para cada clasificador:\n",
        "   - Define el espacio de búsqueda de hiperparámetros.\n",
        "   - Usa **validación cruzada 5-fold** sobre el conjunto de entrenamiento para seleccionar los mejores hiperparámetros.\n",
        "   - Emplea una estrategia de búsqueda adecuada:\n",
        "     - **GridSearchCV**: búsqueda exhaustiva (ideal para espacios pequeños).\n",
        "     - **RandomizedSearchCV**: búsqueda aleatoria (más eficiente con espacios amplios).\n",
        "     - **Bayesian Optimization** (opcional): para búsquedas más inteligentes, usando librerías como `optuna` o `skopt`.\n",
        "3. Guarda el mejor modelo encontrado para cada clasificador con su configuración óptima.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87cd1be",
      "metadata": {
        "id": "f87cd1be"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Entrenamiento: {X_train.shape}, Validación: {X_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "850e98ec",
      "metadata": {
        "id": "850e98ec"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_knn.fit(X_train, y_train)\n",
        "\n",
        "best_knn = grid_knn.best_estimator_\n",
        "print(\"🏆 Mejor KNN:\", grid_knn.best_params_)\n",
        "print(classification_report(y_val, best_knn.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34cc6ca0",
      "metadata": {
        "id": "34cc6ca0"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "y_pred_gnb = gnb.predict(X_val)\n",
        "print(\"📊 Gaussian Naive Bayes:\")\n",
        "print(classification_report(y_val, y_pred_gnb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da7bc6f7",
      "metadata": {
        "id": "da7bc6f7"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid_lr = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'solver': ['lbfgs', 'liblinear'],\n",
        "    'max_iter': [500]\n",
        "}\n",
        "\n",
        "grid_lr = GridSearchCV(LogisticRegression(multi_class='auto'), param_grid_lr, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_lr.fit(X_train, y_train)\n",
        "\n",
        "best_lr = grid_lr.best_estimator_\n",
        "print(\"🏆 Mejor Logistic Regression:\", grid_lr.best_params_)\n",
        "print(classification_report(y_val, best_lr.predict(X_val)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1fca347",
      "metadata": {
        "id": "f1fca347"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "param_grid_dt = {\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_dt = GridSearchCV(DecisionTreeClassifier(), param_grid_dt, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_dt.fit(X_train, y_train)\n",
        "\n",
        "best_dt = grid_dt.best_estimator_\n",
        "print(\"🏆 Mejor Árbol de Decisión:\", grid_dt.best_params_)\n",
        "print(classification_report(y_val, best_dt.predict(X_val)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cdbe3e3",
      "metadata": {
        "id": "5cdbe3e3"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf']\n",
        "}\n",
        "\n",
        "grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "best_svm = grid_svm.best_estimator_\n",
        "print(\"🏆 Mejor SVM:\", grid_svm.best_params_)\n",
        "print(classification_report(y_val, best_svm.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38458a23",
      "metadata": {
        "id": "38458a23"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "best_rf = grid_rf.best_estimator_\n",
        "print(\"🏆 Mejor Random Forest:\", grid_rf.best_params_)\n",
        "print(classification_report(y_val, best_rf.predict(X_val)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64de7a7c",
      "metadata": {
        "id": "64de7a7c"
      },
      "source": [
        "---\n",
        "\n",
        "## Paso 5: Crear una tabla resumen de los mejores modelos\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "Después de entrenar y optimizar todos los clasificadores, debes construir una **tabla resumen en formato Markdown** que incluya:\n",
        "\n",
        "- El **nombre del modelo**\n",
        "- Los **hiperparámetros óptimos** encontrados mediante validación cruzada\n",
        "\n",
        "### Requisitos:\n",
        "\n",
        "- La tabla debe estar escrita en formato **Markdown**.\n",
        "- Cada fila debe corresponder a uno de los modelos evaluados.\n",
        "- Incluye solo los **mejores hiperparámetros** para cada modelo, es decir, aquellos que produjeron el mayor rendimiento en la validación cruzada (accuracy o F1-score).\n",
        "- No incluyas aún las métricas de evaluación (eso se hará en el siguiente paso).\n",
        "\n",
        "### Ejemplo de formato:\n",
        "\n",
        "\n",
        "| Modelo                 | Hiperparámetros óptimos                            |\n",
        "|------------------------|----------------------------------------------------|\n",
        "| KNN                    | n_neighbors=5, weights='distance'                  |\n",
        "| Gaussian Naive Bayes   | var_smoothing=1e-9 (por defecto)                   |\n",
        "| Regresión Logística    | C=1.0, solver='lbfgs'                              |\n",
        "| Árbol de Decisión      | max_depth=10, criterion='entropy'                  |\n",
        "| SVM                    | C=10, kernel='rbf', gamma='scale'                  |\n",
        "| Random Forest          | n_estimators=200, max_depth=20                     |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5db06abe",
      "metadata": {
        "id": "5db06abe"
      },
      "source": [
        "# tu tabla de resultados aquí"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc8951e6",
      "metadata": {
        "id": "bc8951e6"
      },
      "source": [
        "---\n",
        "\n",
        "## Paso 6: Preparar los datos finales para evaluación\n",
        "\n",
        "**Objetivo:**\n",
        "Cargar el dataset de entrenamiento y prueba, limpiar las columnas innecesarias, ajustar los valores de señal, y dejar los datos listos para probar los modelos entrenados.\n",
        "\n",
        "**Instrucciones:**\n",
        "Implementa una función que:\n",
        "- Cargue los archivos `trainingData.csv` y `validationData.csv`\n",
        "- Elimine las columnas irrelevantes (`LONGITUDE`, `LATITUDE`, `SPACEID`, `RELATIVEPOSITION`, `USERID`, `PHONEID`, `TIMESTAMP`)\n",
        "- Reemplace los valores `100` por `-100` en las columnas `WAP001` a `WAP520`\n",
        "- Separe las características (`X`) y la variable objetivo (`FLOOR`)\n",
        "- Devuelva los conjuntos `X_train`, `X_test`, `y_train`, `y_test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2519692",
      "metadata": {
        "id": "a2519692"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def preparar_datos_finales(train_path='trainingData.csv', test_path='validationData.csv'):\n",
        "    # 1. Cargar los archivos\n",
        "    df_train = pd.read_csv(train_path)\n",
        "    df_test = pd.read_csv(test_path)\n",
        "\n",
        "    # 2. Columnas irrelevantes a eliminar\n",
        "    columnas_a_eliminar = ['LONGITUDE', 'LATITUDE', 'SPACEID',\n",
        "                           'RELATIVEPOSITION', 'USERID', 'PHONEID', 'TIMESTAMP']\n",
        "\n",
        "    # Eliminar solo si existen (por seguridad)\n",
        "    df_train = df_train.drop(columns=[col for col in columnas_a_eliminar if col in df_train.columns])\n",
        "    df_test = df_test.drop(columns=[col for col in columnas_a_eliminar if col in df_test.columns])\n",
        "\n",
        "    # 3. Reemplazar 100 por -100 en las columnas WAP001 a WAP520\n",
        "    wap_cols = [col for col in df_train.columns if col.startswith('WAP')]\n",
        "    df_train[wap_cols] = df_train[wap_cols].replace(100, -100)\n",
        "    df_test[wap_cols] = df_test[wap_cols].replace(100, -100)\n",
        "\n",
        "    # 4. Separar características y variable objetivo\n",
        "    X_train = df_train[wap_cols]\n",
        "    y_train = df_train['FLOOR']\n",
        "\n",
        "    X_test = df_test[wap_cols]\n",
        "    y_test = df_test['FLOOR']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1e1611e",
      "metadata": {
        "id": "a1e1611e"
      },
      "source": [
        "---\n",
        "\n",
        "## Paso 7: Evaluar modelos optimizados en el conjunto de prueba\n",
        "\n",
        "**Objetivo:**\n",
        "Evaluar el rendimiento real de los modelos optimizados usando el conjunto de prueba (`X_test`, `y_test`), previamente separado. Cada modelo debe ser entrenado nuevamente sobre **todo el conjunto de entrenamiento** (`X_train`, `y_train`) con sus mejores hiperparámetros, y luego probado en `X_test`.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1. Para cada modelo:\n",
        "   - Usa los **hiperparámetros óptimos** encontrados en el Paso 4.\n",
        "   - Entrena el modelo con `X_train` y `y_train`.\n",
        "   - Calcula y guarda:\n",
        "     - `Accuracy`\n",
        "     - `Precision` (macro)\n",
        "     - `Recall` (macro)\n",
        "     - `F1-score` (macro)\n",
        "     - `AUC` (promedio one-vs-rest si es multiclase)\n",
        "     - Tiempo de entrenamiento (`train_time`)\n",
        "     - Tiempo de predicción (`test_time`)\n",
        "2. Muestra todos los resultados en una **tabla comparativa**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10347fe7",
      "metadata": {
        "id": "10347fe7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import time\n",
        "import pandas as pd\n",
        "def preparar_datos_finales(train_path='trainingData.csv', test_path='validationData.csv'):\n",
        "    import pandas as pd\n",
        "\n",
        "    # Cargar archivos CSV\n",
        "    df_train = pd.read_csv(train_path)\n",
        "    df_test = pd.read_csv(test_path)\n",
        "\n",
        "    # Columnas a eliminar\n",
        "    columnas_a_eliminar = ['LONGITUDE', 'LATITUDE', 'SPACEID',\n",
        "                           'RELATIVEPOSITION', 'USERID', 'PHONEID', 'TIMESTAMP']\n",
        "\n",
        "    # Eliminar columnas irrelevantes si existen\n",
        "    df_train = df_train.drop(columns=[col for col in columnas_a_eliminar if col in df_train.columns])\n",
        "    df_test = df_test.drop(columns=[col for col in columnas_a_eliminar if col in df_test.columns])\n",
        "\n",
        "    # Reemplazar 100 por -100\n",
        "    wap_cols = [col for col in df_train.columns if col.startswith('WAP')]\n",
        "    df_train[wap_cols] = df_train[wap_cols].replace(100, -100)\n",
        "    df_test[wap_cols] = df_test[wap_cols].replace(100, -100)\n",
        "\n",
        "    # Separar características y variable objetivo\n",
        "    X_train = df_train[wap_cols]\n",
        "    y_train = df_train['FLOOR']\n",
        "    X_test = df_test[wap_cols]\n",
        "    y_test = df_test['FLOOR']\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train_final, X_test_final, y_train_final, y_test_final = preparar_datos_finales()\n",
        "\n",
        "# Evaluar todos los modelos\n",
        "resultados_modelos = []\n",
        "\n",
        "for nombre, modelo in modelos.items():\n",
        "    print(f\"⏳ Evaluando: {nombre}\")\n",
        "    resultados = evaluar_modelo(modelo, X_train_final, y_train_final, X_test_final, y_test_final)\n",
        "    resultados['modelo'] = nombre\n",
        "    resultados_modelos.append(resultados)\n",
        "\n",
        "# Mostrar tabla de resultados\n",
        "df_resultados = pd.DataFrame(resultados_modelos)\n",
        "df_resultados = df_resultados[['modelo', 'accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'auc_macro', 'train_time', 'test_time']]\n",
        "df_resultados.sort_values(by='f1_macro', ascending=False, inplace=True)\n",
        "df_resultados.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df_resultados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efcf813b",
      "metadata": {
        "id": "efcf813b"
      },
      "source": [
        "---\n",
        "## Paso 8: Selección y justificación del mejor modelo\n",
        "\n",
        "**Objetivo:**\n",
        "Analizar los resultados obtenidos en el paso anterior y **emitir una conclusión razonada** sobre cuál de los modelos evaluados es el más adecuado para la tarea de predicción del piso en el dataset UJIIndoorLoc.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "- Observa la tabla comparativa del Paso 7 y responde:\n",
        "  - ¿Qué modelo obtuvo el **mejor rendimiento general** en términos de **accuracy** y **F1-score**?\n",
        "  - ¿Qué tan consistente fue su rendimiento en **precision** y **recall**?\n",
        "  - ¿Tiene un **tiempo de entrenamiento o inferencia** excesivamente alto?\n",
        "  - ¿El modelo necesita **normalización**, muchos recursos o ajustes delicados?\n",
        "- Basándote en estos aspectos, **elige un solo modelo** como el mejor clasificador para esta tarea.\n",
        "- **Justifica tu elección** considerando tanto el desempeño como la eficiencia y facilidad de implementación.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7a61042",
      "metadata": {
        "id": "e7a61042"
      },
      "source": [
        "# tu respuesta aquí\n",
        "\n",
        "#### 📋 Tabla resumen de modelos y sus mejores hiperparámetros\n",
        "\n",
        "| Modelo                  | Hiperparámetros óptimos                                              |\n",
        "|-------------------------|-----------------------------------------------------------------------|\n",
        "| KNN                     | `n_neighbors=5`, `weights='distance'`, `metric='manhattan'`          |\n",
        "| Gaussian Naive Bayes    | No requiere ajuste (usa valores por defecto)                         |\n",
        "| Regresión Logística     | `C=1`, `solver='liblinear'`, `max_iter=500`                          |\n",
        "| Árbol de Decisión       | `max_depth=20`, `min_samples_split=5`                                |\n",
        "| SVM                     | `C=10`, `kernel='rbf'`, `probability=True`                           |\n",
        "| Random Forest           | `n_estimators=100`, `max_depth=None`, `min_samples_split=2`          |\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Modelo Seleccionado: **SVM (Support Vector Machine)**\n",
        "\n",
        "#### Justificación:\n",
        "\n",
        "1. **Rendimiento predictivo sobresaliente:**\n",
        "   - Obtuvo la mayor **accuracy** (`0.9217`) y **F1-score macro** (`0.9148`) entre todos los modelos evaluados.\n",
        "   - Además, tuvo **alta precision (`0.9100`) y recall (`0.9210`)**, indicando equilibrio y bajo sesgo.\n",
        "\n",
        "2. **Capacidad de discriminación:**\n",
        "   - El valor de **AUC macro = 0.9848** muestra un excelente rendimiento multiclase.\n",
        "\n",
        "3. **Tiempo y eficiencia:**\n",
        "   - Aunque el tiempo de entrenamiento fue el más alto (`71.7s`), el de inferencia (`1.82s`) es aceptable.\n",
        "   - No es el más rápido, pero su **desempeño justifica el costo computacional**.\n",
        "\n",
        "4. **Implementación:**\n",
        "   - Requiere normalización y ajuste fino de hiperparámetros, pero no necesita cambios frecuentes una vez afinado.\n",
        "\n",
        "---\n",
        "\n",
        "### 🏁 Conclusión:\n",
        "\n",
        "**SVM** es el modelo más adecuado para predecir el piso en entornos interiores usando el dataset UJIIndoorLoc. Su desempeño superior, estabilidad y capacidad de generalización lo convierten en la opción ideal para esta tarea.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f47b37a",
      "metadata": {
        "id": "8f47b37a"
      },
      "source": [
        "---\n",
        "\n",
        "## Rúbrica de Evaluación\n",
        "\n",
        "| Paso | Descripción | Puntuación |\n",
        "|------|-------------|------------|\n",
        "| 1 | Cargar y explorar el dataset | 5 |\n",
        "| 2 | Preparar los datos | 5 |\n",
        "| 3 | Preprocesamiento de las señales WiFi | 10 |\n",
        "| 4 | Entrenamiento y optimización de hiperparámetros | 40 |\n",
        "| 5 | Crear una tabla resumen de los mejores modelos | 5 |\n",
        "| 6 | Preparar los datos finales para evaluación | 5 |\n",
        "| 7 | Evaluar modelos optimizados en el conjunto de prueba | 10 |\n",
        "| 8 | Selección y justificación del mejor modelo | 20 |\n",
        "| **Total** | | **100** |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}